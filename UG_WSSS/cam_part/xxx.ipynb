{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, List\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "from torch import Tensor\n",
    "from matplotlib import cm\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 7, 7])\n",
      "<PIL.Image.Image image mode=F size=1200x1199 at 0x7FCA994592E0>\n"
     ]
    }
   ],
   "source": [
    "img_path = \"/home/jaye/Documents/DeepLearning/08_ConvTrans/cat.jpg\"     # 输入图片的路径\n",
    "save_path = './cat_cam.jpg'    # 类激活图保存路径\n",
    "preprocess = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "net = models.resnet18(pretrained=True)  # 导入模型\n",
    "feature_map = []     # 建立列表容器，用于盛放输出特征图\n",
    "\n",
    "def forward_hook(module, inp, outp):     # 定义hook\n",
    "    feature_map.append(outp)    # 把输出装入字典feature_map\n",
    "\n",
    "net.layer4.register_forward_hook(forward_hook)    # 对net.layer4这一层注册前向传播\n",
    "orign_img = Image.open(img_path).convert('RGB')    # 打开图片并转换为RGB模型\n",
    "img = preprocess(orign_img)     # 图片预处理\n",
    "img = torch.unsqueeze(img, 0)     # 增加batch维度 [1, 3, 224, 224]\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = net(img)     # 前向传播\n",
    "    print(feature_map[0].size())\n",
    "\n",
    "cls = torch.argmax(out).item()    # 获取预测类别编码\n",
    "weights = net._modules.get('fc').weight.data[cls,:]    # 获取类别对应的权重\n",
    "cam = (weights.view(*weights.shape, 1, 1) * feature_map[0].squeeze(0)).sum(0)\n",
    "def _normalize(cams: Tensor) -> Tensor:\n",
    "        \"\"\"CAM normalization\"\"\"\n",
    "        cams.sub_(cams.flatten(start_dim=-2).min(-1).values.unsqueeze(-1).unsqueeze(-1))\n",
    "        cams.div_(cams.flatten(start_dim=-2).max(-1).values.unsqueeze(-1).unsqueeze(-1))\n",
    "\n",
    "        return cams\n",
    "def overlay_mask(img: Image.Image, mask: Image.Image, colormap: str = 'jet', alpha: float = 0.6) -> Image.Image:\n",
    "    \"\"\"Overlay a colormapped mask on a background image\n",
    "\n",
    "    Args:\n",
    "        img: background image\n",
    "        mask: mask to be overlayed in grayscale\n",
    "        colormap: colormap to be applied on the mask\n",
    "        alpha: transparency of the background image\n",
    "\n",
    "    Returns:\n",
    "        overlayed image\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(img, Image.Image) or not isinstance(mask, Image.Image):\n",
    "        raise TypeError('img and mask arguments need to be PIL.Image')\n",
    "\n",
    "    if not isinstance(alpha, float) or alpha < 0 or alpha >= 1:\n",
    "        raise ValueError('alpha argument is expected to be of type float between 0 and 1')\n",
    "\n",
    "    cmap = cm.get_cmap(colormap)    \n",
    "    # Resize mask and apply colormap\n",
    "    overlay = mask.resize(img.size, resample=Image.BICUBIC)\n",
    "    print(overlay)\n",
    "    overlay = (255 * cmap(np.asarray(overlay) ** 2)[:, :, 1:])\n",
    "    # Overlay the image with the mask\n",
    "    overlayed_img = Image.fromarray((alpha * np.asarray(img) + (1 - alpha) * overlay).astype(np.uint8))\n",
    "\n",
    "    return overlayed_img\n",
    "\n",
    "cam = _normalize(F.relu(cam, inplace=True)).cpu()\n",
    "mask = to_pil_image(cam.detach().numpy(), mode='F')\n",
    "result = overlay_mask(orign_img, mask) \n",
    "result.show()\n",
    "result.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c9c21c706ebf972d64f3012a5c3e1e7a56be9882271c91a7d0ccffdcc0e1451"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
